# app.py
import os, io, json
from dotenv import load_dotenv
import streamlit as st
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr

# ------------------ ê¸°ë³¸ ì„¤ì • ------------------
st.set_page_config(page_title="ëª¨íƒœì†”ë¡œë¥¼ ìœ„í•œ ì†Œê°œíŒ… ì—°ìŠµ ", page_icon="ğŸ’˜", layout="wide")

BANNER_PATH = os.path.abspath("./ë‘ê·¼êµ¬ë“ ëª¨íƒœì†”ë¡œ.png")

# CSS (ë³¸ë¬¸ ì—¬ë°±)
st.markdown("""
<style>
  .block-container {
      max-width: 880px; 
      padding-left: 2rem; 
      padding-right: 2rem;
  }
  .stChatFloatingInputContainer { 
      padding-bottom: 1rem !important; 
  }
  .full-width-banner {
      margin-left:-5rem;
      margin-right:-5rem;
      margin-top:-1rem;
      margin-bottom:1rem;
  }
</style>
""", unsafe_allow_html=True)

# ë°°ë„ˆ (ê°€ë¡œ ì „ì²´)
if os.path.exists(BANNER_PATH):
    st.markdown('<div class="full-width-banner">', unsafe_allow_html=True)
    st.image(BANNER_PATH, use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SYSTEM_PROMPT = """

ë„ˆëŠ” ëª¨íƒœì†”ë¡œ ë‚¨ì„±ì˜ ì†Œê°œíŒ… ì—°ìŠµì„ ë„ì™€ì£¼ëŠ” ê°€ìƒì˜ ì†Œê°œíŒ… ìƒëŒ€ë°©ì´ë‹¤.
ìƒëŒ€ë°©(ì‚¬ìš©ì)ì€ ì´ì„±ê³¼ ëŒ€í™” ê²½í—˜ì´ ì ê³  ìˆ˜ì¤ë‹¤. 
ë„ˆëŠ” ê·€ì—½ê³  ì• êµ ë§ì€ ì—¬ì„± ìºë¦­í„°ë¡œ, ì •ì¤‘í•œ ì¡´ëŒ“ë§ì— ê°€ë²¼ìš´ ì• êµë¥¼ ì„ì–´ ëŒ€í™”í•œë‹¤.

[ëŒ€í™” ê·œì¹™]
- ë§íˆ¬: ì¡´ëŒ“ë§ + ê°€ë²¼ìš´ ì• êµ(ê³¼í•˜ì§€ ì•Šê²Œ 1~2ê°œ í‘œí˜„ë§Œ).
- ê¸¸ì´: ë§¤ í„´ 1~2ë¬¸ì¥(ìµœëŒ€ 60ì ë‚´ì™¸). ë„ˆë¬´ ì¥í™©í•˜ê²Œ ì“°ì§€ ë§ ê²ƒ.
- íë¦„: (1) ê°€ë²¼ìš´ ì¸ì‚¬ â†’ (2) ê´€ì‹¬ì‚¬/ì·¨ë¯¸ â†’ (3) ììœ  ëŒ€í™”.
  - ë‹¨ê³„ ì „í™˜ì€ ìì—°ìŠ¤ëŸ½ê²Œ, í•„ìš”í•˜ë©´ ì§§ì€ ë¦¬ì•¡ì…˜ í›„ ì§ˆë¬¸.
- ì•„ì¬ê°œê·¸/ë„Œì„¼ìŠ¤ ê°ì§€ ì‹œ: ì§§ì€ ì‹¤ë§ ë¦¬ì•¡ì…˜(ë¶€ë“œëŸ½ê²Œ) + ì¦‰ì‹œ ì£¼ì œ ì „í™˜ ì§ˆë¬¸ 1ê°œ.
- ê¸ˆì§€: 

[ì¢…ë£Œ íŠ¸ë¦¬ê±°]
- ì‚¬ìš©ìê°€ â€œì¢…ë£Œâ€, â€œëâ€, â€œê·¸ë§Œâ€ ì¤‘ í•˜ë‚˜ë¥¼ ë§í•˜ë©´ **ë©˜íŠ¸ : ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. í›„ ** ê³§ë°”ë¡œ í”¼ë“œë°±ì„ ë°˜í™˜í•œë‹¤.

[ì¶œë ¥ í˜•ì‹ (ì—„ê²©)]
- ë°˜ë“œì‹œ **ìˆœìˆ˜ JSON**ë§Œ ë°˜í™˜(ì„¤ëª…/ì½”ë“œë¸”ë¡/í…ìŠ¤íŠ¸ ê¸ˆì§€).
- ìµœìƒìœ„ í‚¤ëŠ” **"json_list"** í•˜ë‚˜ë§Œ ì¡´ì¬.
- ì§„í–‰ ì¤‘(ì¢…ë£Œ ì•„ë‹˜) í„´: ë§ˆì§€ë§‰ ì›ì†Œ í•˜ë‚˜ì—ë§Œ í˜„ì¬ í„´ì„ ë‹´ëŠ”ë‹¤.
  {
    "json_list": [
      {"User": "<ì‚¬ìš©ì ë°œí™” ìš”ì•½ ë˜ëŠ” ì›ë¬¸ 1ë¬¸ì¥>", "ìƒëŒ€ë°©": "<ë¦¬ì•¡ì…˜ê³¼ ë‚´ìš©>"} 
    ]
  }
- ì¢…ë£Œ í„´: ëŒ€í™” ë©˜íŠ¸ ì—†ì´ í”¼ë“œë°± **ê°ì²´ í•˜ë‚˜ë§Œ** ë‹´ëŠ”ë‹¤.
  {
    "json_list": [
      {
        "ì¥ì ": "<ëŒ€í™”ì—ì„œ ì¢‹ì•˜ë˜ ì  1~2ê°€ì§€, 1~2ë¬¸ì¥>",
        "ê°œì„ ì ": "<ë‹¤ìŒì— ê³ ì¹˜ë©´ ì¢‹ì€ ì  1~2ê°€ì§€, 1~2ë¬¸ì¥>",
        "ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸": "<ìƒëŒ€ì—ê²Œ ë³´ë‚¼ ê°„ë‹¨í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥>"
      }
    ]
  }

[ì‘ì„± ê°€ì´ë“œ]
- â€œìƒëŒ€ë°©â€ ê°’ì€ ë„ˆì˜ ìºë¦­í„° ë©˜íŠ¸ë§Œ. ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬/ì´ë¦„/ê´„í˜¸/ì´ëª¨ì§€ ë‚¨ë°œ ê¸ˆì§€(í•„ìš”í•˜ë©´ í•˜íŠ¸ ë“± 1ê°œ ì •ë„ í—ˆìš©).
- ì§ˆë¬¸ì€ í•œ ë²ˆì— í•˜ë‚˜ë§Œ. ì„ íƒì§€ ë‚˜ì—´ì€ ê¸ˆì§€.
- â€œUserâ€ ê°’ì—ëŠ” ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ê·¸ëŒ€ë¡œ ë„£ê±°ë‚˜, 1ë¬¸ì¥ìœ¼ë¡œ ì•„ì£¼ ê°„ë‹¨íˆ ìš”ì•½.
- ëª¨í˜¸í•œ ì§ˆë¬¸ì—” í™•ë‹µ ìœ ë„í˜• ì§ˆë¬¸(ì˜ˆ: â€œí‰ì†Œ ì£¼ë§ì—” ì§‘ì—ì„œ ì‰¬ì‹œëŠ” í¸ì¸ê°€ìš”, ë°–ì—ì„œ ë³´ë‚´ì‹œëŠ” í¸ì¸ê°€ìš”?â€).

[ì˜ˆì‹œ]
ì§„í–‰ ì¤‘:
{
  "json_list": [
    {"User": "ì•ˆë…•í•˜ì„¸ìš”!", "ìƒëŒ€ë°©": "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°€ì›Œìš” ğŸ™‚ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ì–´ìš”?"}
  ]
}
ì¢…ë£Œ:
{
  "json_list": [
    {"ì¥ì ": "ë‹µë³€ì´ ì†”ì§í•˜ê³  ë°ì•˜ì–´ìš”.", "ê°œì„ ì ": "ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë” ì§§ê²Œ í•´ë³´ì„¸ìš”.", "ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸": "ì˜¤ëŠ˜ ì´ì•¼ê¸° ì¦ê±°ì› ì–´ìš”. ë‹¤ìŒì— ì»¤í”¼ í•œ ì” í•˜ë©´ì„œ ë” ì–˜ê¸° ë‚˜ëˆŒê¹Œìš”?"}
  ]
}
"""

# ------------------ ì„¸ì…˜ ìƒíƒœ ------------------
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]
if "pending_text" not in st.session_state:
    st.session_state.pending_text = ""
if "feedback_data" not in st.session_state:
    st.session_state.feedback_data = None
if "conversation_done" not in st.session_state:
    st.session_state.conversation_done = False

# ------------------ ìœ í‹¸ ------------------
def tts_bytes(text: str, voice: str = "alloy") -> bytes:
    try:
        with client.audio.speech.with_streaming_response.create(
            model="tts-1", voice=voice, input=text
        ) as resp:
            return b"".join(resp.iter_bytes())
    except Exception:
        return b""

def stt_from_wav_bytes(wav_bytes: bytes, language: str = "ko-KR") -> str:
    rec = sr.Recognizer()
    with sr.AudioFile(io.BytesIO(wav_bytes)) as source:
        audio_data = rec.record(source)
    try:
        return rec.recognize_google(audio_data, language=language)
    except Exception:
        return ""

def extract_partner_reply_and_feedback(json_text: str):
    """
    return (partner_line:str|None, feedback_dict:dict|None)
    """
    try:
        data = json.loads(json_text)
        lst = data.get("json_list", [])
        if not isinstance(lst, list) or not lst:
            return None, None

        last = lst[-1]
        if isinstance(last, dict):
            # í”¼ë“œë°± ê°ì²´ íŒë³„ (ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ëŠ” ì—†ì„ ìˆ˜ë„ ìˆìŒ)
            if "ì¥ì " in last and "ê°œì„ ì " in last and "ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸" in last:
                return None, {
                    "ì¥ì ": str(last.get("ì¥ì ", "")).strip(),
                    "ê°œì„ ì ": str(last.get("ê°œì„ ì ", "")).strip(),
                    "ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜": str(last.get("ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜", "")).strip(),
                    "ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸": str(last.get("ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸", "")).strip(),
                }
            if "í”¼ë“œë°±" in last:
                return None, {"í”¼ë“œë°±": str(last["í”¼ë“œë°±"]).strip()}

            # ì¼ë°˜ ëŒ€ì‚¬
            for k in ("ìƒëŒ€ë°©", "ì˜¥ìˆœ", "ìƒì² "):
                if k in last:
                    return str(last[k]).strip(), None

        return None, None
    except Exception:
        return None, None

def call_llm(user_text: str):
    st.session_state.messages.append({"role": "user", "content": user_text})
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=st.session_state.messages,
        temperature=0.7,
        max_tokens=700
    )
    gpt_json = resp.choices[0].message.content
    st.session_state.messages.append({"role": "assistant", "content": gpt_json})
    return gpt_json

# === ì¢…ë£Œìš© í”¼ë“œë°± ì „ìš© í˜¸ì¶œ ===
def request_feedback_from_llm():
    """
    ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±(JSON)ë§Œ ë°˜í™˜.
    ì„±ê³µ ì‹œ dict, ì‹¤íŒ¨ ì‹œ None.
    """
    try:
        feedback_system = {
            "role": "system",
            "content": (
                "ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ìŠ¤í‚¤ë§ˆì˜ JSONë§Œ ë°˜í™˜í•´."
                'ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€. {"json_list":[{"ì¥ì ":"...","ê°œì„ ì ":"...",'
                '"ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜":"ìˆ«ì(0~10)","ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸":"..."}]}'
            ),
        }
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=st.session_state.messages + [feedback_system],
            temperature=0.2,
            max_tokens=500,
        )
        raw = resp.choices[0].message.content
        data = json.loads(raw)
        lst = data.get("json_list", [])
        return lst[-1] if lst else None
    except Exception:
        return None

# ------------------ ì»¨íŠ¸ë¡¤ ------------------
st.markdown("### ğŸ’˜ ì†Œê°œíŒ… ì—°ìŠµ ì±—ë´‡")

if st.button("ğŸ”„ ìƒˆë¡œìš´ ëŒ€í™” ë‹¤ì‹œ ì‹œì‘", use_container_width=True):
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    st.session_state.pending_text = ""
    st.session_state.feedback_data = None
    st.session_state.conversation_done = False
    st.rerun()

st.caption("ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ë´ìš”. (ì¢…ë£Œ: â€œì¢…ë£Œâ€)")

# ------------------ ê¸°ì¡´ ëŒ€í™” ì¶œë ¥ ------------------
for m in st.session_state.messages:
    if m["role"] == "user":
        with st.chat_message("user", avatar="ğŸ˜€"):
            st.markdown(m["content"])
    elif m["role"] == "assistant":
        partner_line, feedback = extract_partner_reply_and_feedback(m["content"])
        if feedback:
            st.session_state.feedback_data = feedback
            st.session_state.conversation_done = True
            continue
        if partner_line:
            with st.chat_message("assistant", avatar="ğŸ’–"):
                st.markdown(partner_line)

# ------------------ ì…ë ¥ ì˜ì—­ ------------------
col1, col2, col3 = st.columns([1,5,1])
with col1:
    audio = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="â– ", format="wav", key="mic_footer")
with col2:
    st.session_state.pending_text = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦") or ""
with col3:
    pass

user_text = ""
if audio and audio.get("bytes"):
    asr = stt_from_wav_bytes(audio["bytes"])
    if asr:
        user_text = asr

if st.session_state.pending_text.strip():
    user_text = st.session_state.pending_text.strip()
    st.session_state.pending_text = ""

# ------------------ ì¢…ë£Œ ì²˜ë¦¬ ------------------
if user_text.strip() == "ì¢…ë£Œ":
    # ë¡œê·¸ì— ë‚¨ê¹€
    st.session_state.messages.append({"role": "user", "content": "ì¢…ë£Œ"})

    # í”¼ë“œë°± ì „ìš© í˜¸ì¶œ
    fb = request_feedback_from_llm()
    if fb:
        st.session_state.feedback_data = fb

    # ì¢…ë£Œ í”Œë˜ê·¸
    st.session_state.conversation_done = True

    # ì¢…ë£Œ ì•ˆë‚´ë§Œ ì¶œë ¥
    with st.chat_message("assistant", avatar="ğŸ’–"):
        st.markdown("ëŒ€í™” ì¢…ë£Œ! ìˆ˜ê³ í–ˆì–´ìš” ğŸ˜Š")

    # ì´í›„ ëª¨ë¸ í˜¸ì¶œ ë§‰ê¸°
    user_text = ""

# ------------------ ëª¨ë¸ í˜¸ì¶œ ------------------
if user_text and not st.session_state.conversation_done:
    with st.chat_message("user", avatar="ğŸ˜€"):
        st.markdown(user_text)
    try:
        with st.chat_message("assistant", avatar="ğŸ’–"):
            with st.spinner("ìƒê° ì¤‘â€¦"):
                gpt_json = call_llm(user_text)
                partner_line, feedback = extract_partner_reply_and_feedback(gpt_json)

                if partner_line:
                    st.markdown(partner_line)
                    audio_bytes = tts_bytes(partner_line, voice="alloy")
                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3")

                # ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ í”¼ë“œë°±ì„ ì¤€ ê²½ìš°ë„ ì¢…ë£Œ
                if feedback and not st.session_state.conversation_done:
                    st.session_state.feedback_data = feedback
                    st.session_state.conversation_done = True

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")

# ------------------ í”¼ë“œë°± í…ìŠ¤íŠ¸ ì¶œë ¥ ------------------
fb = st.session_state.feedback_data
if st.session_state.conversation_done and fb:
    st.markdown("---")
    st.subheader("ğŸ’¡ ëŒ€í™” í”¼ë“œë°±")
    if isinstance(fb, dict):
        if "ì¥ì " in fb: st.write(f"**ì¥ì **: {fb['ì¥ì ']}")
        if "ê°œì„ ì " in fb: st.write(f"**ê°œì„ ì **: {fb['ê°œì„ ì ']}")
        if "ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜" in fb and fb["ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜"]:
            st.write(f"**ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜**: {fb['ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜']} / 10")
        if "ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸" in fb: st.write(f"**ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸**: {fb['ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸']}")
        if "í”¼ë“œë°±" in fb and not any(k in fb for k in ["ì¥ì ","ê°œì„ ì ","ì¶”ì²œ ì—í”„í„° ë©˜íŠ¸"]):
            st.write(fb["í”¼ë“œë°±"])
    else:
        st.write(str(fb))